{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import \n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bangla_characters(file_name):\n",
    "    char_dict = {}\n",
    "    with open(file_name, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        csv_lines = csv.DictReader(f)\n",
    "        for row in csv_lines:\n",
    "            alphabet = row['alphabet'].strip()\n",
    "            char_dict[alphabet] = True \n",
    "    return char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_path = os.path.join('/home','tiger','Desktop', 'office','bangla-lm','engla', 'resource', 'bn_vowels.csv')\n",
    "consonant_path = os.path.join('/home','tiger','Desktop', 'office','bangla-lm','engla', 'resource', 'bn_consonants.csv')\n",
    "kar_path = os.path.join('/home','tiger','Desktop', 'office','bangla-lm','engla', 'resource', 'bn_kars.csv')\n",
    "bn_vowels = read_bangla_characters(vowel_path)\n",
    "bn_consonants = read_bangla_characters(consonant_path)\n",
    "bn_kars = read_bangla_characters(kar_path)\n",
    "bn_digits = {'০': True, '১': True, '২': True, '৩': True, '৪': True, '৫': True, '৬': True, '৭': True, '৮': True, '৯': True,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(list_of_dict):\n",
    "    global_dict, global_dict2 = {},{}\n",
    "    cnt = 0\n",
    "    for l in list_of_dict:\n",
    "        for key in l:\n",
    "            if global_dict.get(key) is None:\n",
    "                global_dict[key] = cnt \n",
    "                global_dict2[cnt] = key\n",
    "                cnt = cnt + 1 \n",
    "    return global_dict, global_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'অ': 0, 'আ': 1, 'ই': 2, 'ঈ': 3, 'উ': 4, 'ঊ': 5, 'ঋ': 6, 'এ': 7, 'ঐ': 8, 'ও': 9, 'ঔ': 10, 'ক': 11, 'খ': 12, 'গ': 13, 'ঘ': 14, 'ঙ': 15, 'চ': 16, 'ছ': 17, 'জ': 18, 'ঝ': 19, 'ঞ': 20, 'ট': 21, 'ঠ': 22, 'ড': 23, 'ঢ': 24, 'ণ': 25, 'ত': 26, 'থ': 27, 'দ': 28, 'ধ': 29, 'ন': 30, 'প': 31, 'ফ': 32, 'ব': 33, 'ভ': 34, 'ম': 35, 'য': 36, 'র': 37, 'ল': 38, 'শ': 39, 'ষ': 40, 'স': 41, 'হ': 42, 'ড়': 43, 'ঢ়': 44, 'য়': 45, 'ৎ': 46, 'ং': 47, 'ঃ': 48, 'ঁ': 49, 'া': 50, 'ি': 51, 'ী': 52, 'ু': 53, 'ূ': 54, 'ৃ': 55, 'ে': 56, 'ৈ': 57, 'ো': 58, 'ৌ': 59, '০': 60, '১': 61, '২': 62, '৩': 63, '৪': 64, '৫': 65, '৬': 66, '৭': 67, '৮': 68, '৯': 69, '্': 70, '\\u200d': 71, ' ': 72} {0: 'অ', 1: 'আ', 2: 'ই', 3: 'ঈ', 4: 'উ', 5: 'ঊ', 6: 'ঋ', 7: 'এ', 8: 'ঐ', 9: 'ও', 10: 'ঔ', 11: 'ক', 12: 'খ', 13: 'গ', 14: 'ঘ', 15: 'ঙ', 16: 'চ', 17: 'ছ', 18: 'জ', 19: 'ঝ', 20: 'ঞ', 21: 'ট', 22: 'ঠ', 23: 'ড', 24: 'ঢ', 25: 'ণ', 26: 'ত', 27: 'থ', 28: 'দ', 29: 'ধ', 30: 'ন', 31: 'প', 32: 'ফ', 33: 'ব', 34: 'ভ', 35: 'ম', 36: 'য', 37: 'র', 38: 'ল', 39: 'শ', 40: 'ষ', 41: 'স', 42: 'হ', 43: 'ড়', 44: 'ঢ়', 45: 'য়', 46: 'ৎ', 47: 'ং', 48: 'ঃ', 49: 'ঁ', 50: 'া', 51: 'ি', 52: 'ী', 53: 'ু', 54: 'ূ', 55: 'ৃ', 56: 'ে', 57: 'ৈ', 58: 'ো', 59: 'ৌ', 60: '০', 61: '১', 62: '২', 63: '৩', 64: '৪', 65: '৫', 66: '৬', 67: '৭', 68: '৮', 69: '৯', 70: '্', 71: '\\u200d', 72: ' '}\n"
     ]
    }
   ],
   "source": [
    "char2int, int2char = merge_dicts([bn_vowels, bn_consonants, bn_kars, bn_digits])\n",
    "# nukta\n",
    "char2int[chr(2509)] = len(char2int)\n",
    "int2char[len(int2char)] = chr(2509)\n",
    "# additional space \n",
    "char2int[chr(8205)] = len(char2int)\n",
    "int2char[len(int2char)] = chr(8205)\n",
    "# space\n",
    "char2int[\" \"] = len(char2int)\n",
    "int2char[len(int2char)] = \" \"\n",
    "print(char2int, int2char)\n",
    "#print(len(char2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_space(sentence):\n",
    "    temp = \"\"\n",
    "    for i in range(0, len(sentence)):\n",
    "        if i-1 >=0 and sentence[i] == \" \" and temp[-1] == \" \":\n",
    "            continue\n",
    "        temp = temp + sentence[i]\n",
    "    temp = temp.strip()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_symbols(sentence):\n",
    "    temp = \"\"\n",
    "    for i in range(0, len(sentence)):\n",
    "        if sentence[i] == \" \" or sentence[i] == chr(2509) or sentence[i] == chr(8205) or bn_vowels.get(sentence[i]) is not None or bn_consonants.get(sentence[i])is not None or bn_kars.get(sentence[i]) is not None or bn_digits.get(sentence[i]) is not None:\n",
    "            if sentence[i] == \" \":\n",
    "                if temp != \"\" and temp[-1] == ' ':\n",
    "                    continue\n",
    "            temp = temp + sentence[i]   \n",
    "    temp = temp.strip()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bn_sentences(file_name, limit_fix=None):\n",
    "    sentences = []\n",
    "    with open(file_name, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for lines in f:\n",
    "            line = lines.strip()\n",
    "            line = remove_redundant_symbols(line)\n",
    "            if line != \"\":\n",
    "                sentences.append(line)\n",
    "            if len(sentences)%1000 == 0 and len(sentences)>0:\n",
    "                print(len(sentences))\n",
    "            if limit_fix is not None and len(sentences) >= limit_fix:\n",
    "                break\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# reading bangla sentences\n",
    "file_name = os.path.join('/home','tiger','Desktop','office','bangla-data','processed_sentence.txt')\n",
    "sentences = read_bn_sentences(file_name, limit_fix=100000)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['কুটিরখানা শুন্য রেখে চলে যাব সুদূর আকাশে', 'প্রজাপতির ডানায় নতুন পৃথিবী', 'কিছু বিকৃত চোখের তৃষ্ণা মেটানো এবং চরম ব্যবসায়িক মনোভাব এর মূল লক্ষ্য', 'আমি আমার গল্পের ইঞ্জিনিয়ার ছেলেটির প্রতি চেষ্টা করেও নিষ্ঠুর হতে পারি না', 'আমাদের দেশেরই', 'যারাই শুধু ছুতে পারে আমার বিষাদের ইতিবৃত্ত', 'আমি আর নেই', 'তাই এখানে সেখানে বা থাকি যখন যেখানে', 'বিশ্বব্রহ্মাণ্ডে এই দূরত্ব এত বেশি যে বিজ্ঞানীরা একে মাপতে এককের নাম দিয়েছেন লাইট ইয়ার', 'হাতের চিগারেটটা শেষ করে হাটতে লাগল এতীমখানার উদ্দেশে']\n"
     ]
    }
   ],
   "source": [
    "segment = 100000\n",
    "complete_db = sentences\n",
    "sentences = complete_db[:segment]\n",
    "print(sentences[0:min(10, len(sentences))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_sentence = ['আমি ভাত খাই', 'আমি স্কুলে যাই', 'তুমি কি করো']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['আমি ভাত খাই', 'আমি স্কুলে যাই', 'তুমি কি করো']\n"
     ]
    }
   ],
   "source": [
    "sentences = pseudo_sentence\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_sentence_length(sentences):\n",
    "    mean = 0\n",
    "    for i in range(0, len(sentences)):\n",
    "        sentences[i] = sentences[i].strip()\n",
    "        mean = mean + len(sentences[i])\n",
    "    mean = mean / (1.0 * len(sentences))   \n",
    "    mean = math.floor(mean)\n",
    "    print(\"mean {}\".format(mean))\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_too_long_words(sentence):\n",
    "    words = sentence.split(\" \")\n",
    "    s = []\n",
    "    for w in words:\n",
    "        if len(w) >= 25:\n",
    "            return False \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_max_length_process(sentences, start_max_length):\n",
    "    i = 0 \n",
    "    save = []\n",
    "    temp_ml = 0\n",
    "    idx_save = None\n",
    "    while i < len(sentences):\n",
    "        if i%10000 == 0:\n",
    "            print(i)\n",
    "        verdict = check_too_long_words(sentences[i])\n",
    "        # print(verdict, sentences[i])\n",
    "        if verdict is False:\n",
    "            print(verdict, sentences[i])\n",
    "            i = i + 1\n",
    "            continue\n",
    "        if len(sentences[i]) <= start_max_length:\n",
    "            save.append(sentences[i])\n",
    "            temp_ml = max(temp_ml, len(save[-1]))\n",
    "            if temp_ml == len(sentences[i]):\n",
    "                idx_save = len(save)-1\n",
    "            i = i + 1\n",
    "        else:\n",
    "            sentences[i] = sentences[i].strip()\n",
    "            words = sentences[i].split(\" \")\n",
    "            divide = [\"\"]\n",
    "            for j in range(0, len(words)):\n",
    "                if len(divide[-1]) + len(words[j]) > start_max_length:\n",
    "                    divide[-1] = divide[-1].strip()\n",
    "                    divide.append(\"\")\n",
    "                    divide[-1] = words[j]\n",
    "                else:\n",
    "                    divide[-1] = divide[-1] + \" \" + words[j]\n",
    "            for j in range(0, len(divide)):\n",
    "                save.append(divide[j])\n",
    "                temp_ml = max(temp_ml, len(divide[j]))\n",
    "                if temp_ml == len(save[-1]):\n",
    "                    idx_save = len(save)-1\n",
    "            i = i + 1\n",
    "    print(temp_ml, idx_save, save[idx_save])\n",
    "    return save, temp_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_length(sentences, sentence_avg_length):\n",
    "    max_length = 0 \n",
    "    idx = 0\n",
    "    for i in range(0,len(sentences)):\n",
    "        if max_length < len(sentences[i]):\n",
    "            max_length = len(sentences[i])\n",
    "            idx = i\n",
    "    print(max_length, idx, sentences[idx], len(sentences[idx]))\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sentence(sentences, max_length, allowed_gap):\n",
    "    i = 0\n",
    "    save = []\n",
    "    while i<len(sentences):\n",
    "        # print(sentences[i])\n",
    "        if len(sentences[i]) < (max_length-allowed_gap):\n",
    "            i=i+1\n",
    "        else:\n",
    "            save.append(sentences[i])\n",
    "            i=i+1\n",
    "    return save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 44\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(find_mean_sentence_length(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_max_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "False আবার আমরা দেশ প্রেমিকলেখকবিজ্ঞানীগণিতবিদ ও শিল্পী খুজে পাব\n",
      "20000\n",
      "False আর এই দৃশ্য দেখার পর আমার একটা কথায় মনে হয় রুশো মন্টেসরীফ্রয়েবেলরবীন্দ্রনাথ এদের শিক্ষা দর্শন আজ ফিকে হয়ে যাচ্ছে\n",
      "30000\n",
      "False টেলিভিশনপত্রিকাফেসবুকব্লগ ও\n",
      "40000\n",
      "False শিল্প সাহিত্যের জ্ঞান ছড়িয়ে দেবার জন্য বিশ্ববিদ্যালয়পাঠাগারস্কুলকলেজ ভিত্তিক নানান প্রচেষ্টা হাতে নেয়া যেতে পারে\n",
      "50000\n",
      "False কারণ তাঁর চেষ্ঠাপ্রচেষ্ঠাকর্মদক্ষতা ও সচেতনতায় দেশের সবচেয়ে বাল্যবিয়ে প্রবণ উপজেলা সরাইল আজ নিরানব্বই ভাগ বাল্যবিয়ে মুক্ত উপজেলা\n",
      "False দূর থেকে পড়তে না জানলে পুলিশছিনতাইকারীচোরবারবনিতাদের অন্যায় আক্রমনের শিকার হতে পারে যে কোনো সময়\n",
      "60000\n",
      "False নৈতিক শিক্ষাই একজন মানুষকে প্রতারকভন্ডছিনতাইকারীধর্ষকঘুষখোর ও যে কোন দূর্নীতিপরায়ন হয়ে উঠতে বাধা দেয়\n",
      "70000\n",
      "80000\n",
      "False দিনদিন আমরা হয়ে উঠছি ধর্ষকপ্রতারকঘুষখোরছিনতাইকারীসিরিয়াল কিলারবোমাবাজ ভন্ড নেতা উগ্রপন্থী চরমপন্থীসাম্প্রদায়িক কিন্তু কেন এই পরিণতি আমাদের আমাদের তো ছিল সুন্দর ইতিহাস\n",
      "90000\n",
      "False হাইহ্যালোআন্তরিকতাভালোবাসা সবার সাথে আদান প্রদান শেষে আপুকে নিয়ে উদ্যানে ঢুকলাম শাওন ভাই সহ\n",
      "False পোলাপাইন আমার রুমে দরজা আটকে কি যে করতেছেহুড়াহুড়িচেচামেচিখুব মজা হচ্ছে বুঝতেছি\n",
      "24 150159 মৃত্যদন্ডাজ্ঞাপ্রাপ্তদের\n",
      "length =  353813 24\n"
     ]
    }
   ],
   "source": [
    "updated_sentences,sequence_max_length = sentence_max_length_process(sentences, sequence_max_length)\n",
    "print(\"length = \",len(updated_sentences), sequence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132456 24\n"
     ]
    }
   ],
   "source": [
    "updated_sentences = delete_sentence(updated_sentences, sequence_max_length, allowed_gap=10)\n",
    "print(len(updated_sentences), sequence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_sentences(sentences, start_max_length):\n",
    "    for i in range(0, len(sentences)):\n",
    "        while len(sentences[i]) < start_max_length:\n",
    "            sentences[i] = sentences[i]+ \" \"\n",
    "        if len(updated_sentences[i]) != start_max_length:\n",
    "            print(\"violated \", len(updated_sentences[i]), start_max_length)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_sentences = padding_sentences(updated_sentences, sequence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_seq_len(updated_sentences, sequence_max_length):\n",
    "    l = sequence_max_length\n",
    "    for i in range(0, len(updated_sentences)):\n",
    "        if len(updated_sentences[i]) != sequence_max_length:\n",
    "            print(len(updated_sentences[i]))\n",
    "        l = min(l, len(updated_sentences[i]))\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "sanity_check_seq_len(updated_sentences, sequence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_target_make(sentences):\n",
    "    input_sen, target_sen = [], []\n",
    "    for i in range(0, len(sentences)):\n",
    "        input_sen.append(sentences[i][:-1])\n",
    "        target_sen.append(sentences[i][1:])\n",
    "    return input_sen, target_sen\n",
    "def sanity_test_input_target(input_sen, target_sen):\n",
    "    for i in range(0,min(len(input_sen),50)):\n",
    "        print(input_sen[i], target_sen[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "কুটিরখানা শুন্য         ুটিরখানা শুন্য         \n",
      "প্রজাপতির ডানায়         ্রজাপতির ডানায়         \n",
      "মেটানো এবং চরম          েটানো এবং চরম          \n",
      "ব্যবসায়িক মনোভাব        ্যবসায়িক মনোভাব        \n",
      "আমি আমার গল্পের         মি আমার গল্পের         \n",
      "নিষ্ঠুর হতে পারি        িষ্ঠুর হতে পারি        \n",
      "যারাই শুধু ছুতে         ারাই শুধু ছুতে         \n",
      "বিষাদের ইতিবৃত্ত        িষাদের ইতিবৃত্ত        \n",
      "সেখানে বা থাকি          েখানে বা থাকি          \n",
      "বিশ্বব্রহ্মাণ্ডে        িশ্বব্রহ্মাণ্ডে        \n",
      "বিজ্ঞানীরা একে          িজ্ঞানীরা একে          \n",
      "মাপতে এককের নাম         াপতে এককের নাম         \n",
      "হাতের চিগারেটটা         াতের চিগারেটটা         \n",
      "লাগল এতীমখানার          াগল এতীমখানার          \n",
      "বাতাসে বক্ষ ভরি         াতাসে বক্ষ ভরি         \n",
      "স্থানগুলোর ছবি          ্থানগুলোর ছবি          \n",
      "একটা করে পোষ্ট          কটা করে পোষ্ট          \n",
      "কর্মসূত্রে তিনি         র্মসূত্রে তিনি         \n",
      "একসাইটেট স্বপন          কসাইটেট স্বপন          \n",
      "ক্ষেত ধরেই তাদের        ্ষেত ধরেই তাদের        \n",
      "দিল্লিকা লাড্ডু         িল্লিকা লাড্ডু         \n",
      "পিছনের সিটে বসার        িছনের সিটে বসার        \n",
      "বাচ্চাকে যে কেউ         াচ্চাকে যে কেউ         \n",
      "আদর করছে না চুমু        দর করছে না চুমু        \n",
      "খাচ্ছে না তা না         াচ্ছে না তা না         \n",
      "কিরে ব্যাটা কি          িরে ব্যাটা কি          \n",
      "খবর কবে এসেছিস          বর কবে এসেছিস          \n",
      "হয়ে যাবে একসময়          য়ে যাবে একসময়          \n",
      "কি করে এমন কেন          ি করে এমন কেন          \n",
      "বা ভালবেসে ছিলাম        া ভালবেসে ছিলাম        \n",
      "সাধারণ মানুষের          াধারণ মানুষের          \n",
      "এসে জিজ্ঞেস করে         সে জিজ্ঞেস করে         \n",
      "হে রা আপনাকে কি         ে রা আপনাকে কি         \n",
      "সাপে কামড়েছে রা         াপে কামড়েছে রা         \n",
      "বলে তিনি তো সাপ         লে তিনি তো সাপ         \n",
      "তৈরী করেননি তবে         ৈরী করেননি তবে         \n",
      "নির্লিপ্তভাবেই          ির্লিপ্তভাবেই          \n",
      "কোন রকম সেটাকে          োন রকম সেটাকে          \n",
      "সামলে নিয়ে তার          ামলে নিয়ে তার          \n",
      "দার্জিলিং থেকে          ার্জিলিং থেকে          \n",
      "চট্টগ্রাম জেলার         ট্টগ্রাম জেলার         \n",
      "এরমধ্যে সন্ধ্যা         রমধ্যে সন্ধ্যা         \n",
      "কাকাবাবু বললেন          াকাবাবু বললেন          \n",
      "তিনি আজ রাত এই          িনি আজ রাত এই          \n",
      "হাতল ধরে মুখসহ          াতল ধরে মুখসহ          \n",
      "শরীরের অর্ধেকটা         রীরের অর্ধেকটা         \n",
      "কেউ একজন এসে ওর         েউ একজন এসে ওর         \n",
      "যেখানে আমৃত্যু          েখানে আমৃত্যু          \n",
      "তাহলে কি চাস গত         াহলে কি চাস গত         \n",
      "আফেয়ার উহু অন্য         ফেয়ার উহু অন্য         \n"
     ]
    }
   ],
   "source": [
    "input_sen, target_sen = input_target_make(updated_sentences)\n",
    "sanity_test_input_target(input_sen, target_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131950 131950\n"
     ]
    }
   ],
   "source": [
    "print(len(input_sen), len(target_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_int_conversion(sentence):\n",
    "    t = []\n",
    "    # print(char2int)\n",
    "    for i in range(0, len(sentence)):\n",
    "        if char2int.get(sentence[i]) is not None:\n",
    "            t.append(char2int.get(sentence[i]))\n",
    "        else:\n",
    "            t.append(len(char2int))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "[[11, 53, 21, 51, 37, 12, 50, 30, 50, 72, 39, 53, 30, 70, 36, 72, 72, 72, 72, 72, 72, 72, 72], [31, 70, 37, 18, 50, 31, 26, 51, 37, 72, 23, 50, 30, 50, 45, 72, 72, 72, 72, 72, 72, 72, 72], [35, 56, 21, 50, 30, 58, 72, 7, 33, 47, 72, 16, 37, 35, 72, 72, 72, 72, 72, 72, 72, 72, 72], [33, 70, 36, 33, 41, 50, 45, 51, 11, 72, 35, 30, 58, 34, 50, 33, 72, 72, 72, 72, 72, 72, 72], [1, 35, 51, 72, 1, 35, 50, 37, 72, 13, 38, 70, 31, 56, 37, 72, 72, 72, 72, 72, 72, 72, 72], [30, 51, 40, 70, 22, 53, 37, 72, 42, 26, 56, 72, 31, 50, 37, 51, 72, 72, 72, 72, 72, 72, 72], [36, 50, 37, 50, 2, 72, 39, 53, 29, 53, 72, 17, 53, 26, 56, 72, 72, 72, 72, 72, 72, 72, 72], [33, 51, 40, 50, 28, 56, 37, 72, 2, 26, 51, 33, 55, 26, 70, 26, 72, 72, 72, 72, 72, 72, 72], [41, 56, 12, 50, 30, 56, 72, 33, 50, 72, 27, 50, 11, 51, 72, 72, 72, 72, 72, 72, 72, 72, 72], [33, 51, 39, 70, 33, 33, 70, 37, 42, 70, 35, 50, 25, 70, 23, 56, 72, 72, 72, 72, 72, 72, 72]]\n",
      "কুটিরখানা শুন্য         [11, 53, 21, 51, 37, 12, 50, 30, 50, 72, 39, 53, 30, 70, 36, 72, 72, 72, 72, 72, 72, 72, 72] 23\n",
      "ুটিরখানা শুন্য          [53, 21, 51, 37, 12, 50, 30, 50, 72, 39, 53, 30, 70, 36, 72, 72, 72, 72, 72, 72, 72, 72, 72] 23\n"
     ]
    }
   ],
   "source": [
    "input_sen_bit, target_sen_bit, = [],[]\n",
    "for i in range(0, len(input_sen)):\n",
    "    input_sen_bit.append(sequence_to_int_conversion(input_sen[i]))\n",
    "    target_sen_bit.append(sequence_to_int_conversion(target_sen[i]))\n",
    "    # print(input_sen[i], input_sen_bit[-1])\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "print(input_sen_bit[0:10])\n",
    "print(input_sen[0], input_sen_bit[0], len(input_sen_bit[0]))\n",
    "print(target_sen[0], target_sen_bit[0], len(target_sen_bit[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_into_pickle(objs):\n",
    "    # Saving the objects:\n",
    "    with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump(objs, f)\n",
    "        \n",
    "def load_from_pickle():\n",
    "    # Getting back the objects:\n",
    "    with open('objs.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "        objs = pickle.load(f)\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "test = [1,2,3]\n",
    "save_into_pickle([test])\n",
    "objs = load_from_pickle()\n",
    "print(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(char2int)\n",
    "seq_len = sequence_max_length-1\n",
    "batch_size = len(input_sen)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    print(features.shape)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        # print(i, sequence[i], len(sequence[i]))\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132456, 23, 73)\n",
      "Input shape: (132456, 23, 73) --> (Batch Size, Sequence Length, One-Hot Encoding Size)\n"
     ]
    }
   ],
   "source": [
    "input_sen_hot_encode = one_hot_encode(input_sen_bit, dict_size, seq_len, batch_size)\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_sen_hot_encode.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{30: 131950}\n"
     ]
    }
   ],
   "source": [
    "v = {}\n",
    "for i in range(0,len(target_sen_bit)):\n",
    "    if len(target_sen_bit[i]) not in v:\n",
    "        v[len(target_sen_bit[i])] = 0\n",
    "    v[len(target_sen_bit[i])] = v[len(target_sen_bit[i])] + 1\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sen_hot_encode = torch.from_numpy(input_sen_hot_encode)\n",
    "target_sen_hot_encode = torch.Tensor(target_sen_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131950, 30, 73])\n",
      "torch.Size([131950, 30])\n"
     ]
    }
   ],
   "source": [
    "print(input_sen_hot_encode.shape)\n",
    "print(target_sen_hot_encode.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=20, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chekcpoint(epoch, model_path, loss):\n",
    "    EPOCH = epoch\n",
    "    PATH = model_path\n",
    "    LOSS = loss\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': EPOCH,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': LOSS,\n",
    "                }, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(PATH):\n",
    "    if os.path.exists(PATH) is True:\n",
    "        model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=20, n_layers=1)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        checkpoint = torch.load(PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        print(\"checkpoint loaded\")\n",
    "        print(checkpoint['model_state_dict'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return epoch, loss, model, optimizer\n",
    "    else:\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded\n",
      "OrderedDict([('rnn.weight_ih_l0', tensor([[ 0.7722,  0.0673,  0.1678,  ...,  0.0988, -0.0139, -0.0338],\n",
      "        [ 0.5495,  1.2674, -0.3873,  ...,  0.4859, -0.1725, -0.1429],\n",
      "        [ 0.6228,  0.4732, -0.4486,  ...,  1.6023, -0.0264,  0.4706],\n",
      "        ...,\n",
      "        [ 1.5699,  0.9656,  0.0285,  ...,  0.9069, -0.0911, -0.3848],\n",
      "        [-0.4140, -0.0913,  0.1141,  ...,  0.2426,  0.1132, -0.3177],\n",
      "        [-0.0101, -0.9493, -0.1819,  ..., -0.2745,  0.0181,  0.4105]])), ('rnn.weight_hh_l0', tensor([[ 7.8423e-01,  1.3394e-01,  4.4591e-02, -2.9729e-01, -3.4106e-02,\n",
      "          1.7427e-01,  1.0950e-01, -1.3249e-01,  4.1050e-01,  2.3295e-01,\n",
      "          6.4822e-01, -1.8699e-01,  6.9288e-02,  6.9375e-01,  3.6745e-01,\n",
      "         -5.2909e-02, -1.9706e-01,  1.7563e-01,  3.0234e-01, -1.6617e-01],\n",
      "        [ 1.2958e-01, -4.5851e-02, -2.5513e-01, -1.8209e-01,  1.7162e-01,\n",
      "         -2.4502e-01, -3.3332e-01, -2.7899e-02,  9.7448e-04,  3.3103e-01,\n",
      "          4.9150e-04,  4.8055e-02, -2.1716e-01,  9.4001e-02,  7.5834e-02,\n",
      "          2.0788e-01, -5.1101e-02, -1.2142e-01,  2.7899e-01, -3.0972e-01],\n",
      "        [ 6.6555e-02, -4.0609e-01, -3.0159e-01, -4.8454e-02,  2.1087e-01,\n",
      "         -1.5335e-01, -2.5937e-02,  1.1822e-01,  1.1977e-01,  4.1938e-01,\n",
      "          1.3334e-02, -2.8700e-01, -2.4269e-01, -3.4945e-02,  3.6886e-01,\n",
      "          8.2043e-02, -1.6379e-01,  1.1158e-01,  2.1286e-01, -2.9005e-01],\n",
      "        [-1.5108e-01,  1.9646e-01,  9.4546e-02, -2.6708e-01,  1.1838e-01,\n",
      "          2.7077e-01,  3.3935e-02,  3.4156e-02,  1.3437e-01, -3.6765e-01,\n",
      "         -2.0580e-01,  3.6284e-01,  1.4560e-01, -1.3124e-01,  1.1045e-01,\n",
      "         -3.8905e-01,  8.6948e-02,  3.6274e-02, -2.6477e-01,  9.7777e-02],\n",
      "        [-6.0876e-03, -4.3885e-01,  9.2858e-02, -6.4270e-01,  3.2133e-01,\n",
      "          1.3415e-01, -6.2607e-02, -1.3532e-01,  4.7006e-01, -3.5708e-02,\n",
      "         -5.4435e-01, -1.1257e-01, -5.9567e-02,  8.2073e-02, -2.3593e-02,\n",
      "         -3.8395e-05,  1.3376e-01, -3.1936e-02,  2.9555e-01, -4.6729e-01],\n",
      "        [-8.5672e-02,  5.2378e-01,  7.7275e-02,  1.3069e-01, -4.5987e-02,\n",
      "          8.5204e-02,  3.2345e-01, -2.0361e-01, -5.6109e-01,  8.3241e-02,\n",
      "          5.8238e-01,  7.5607e-02,  6.1271e-02, -3.7214e-01, -1.7757e-01,\n",
      "         -4.0110e-02,  1.6045e-02,  1.9118e-01, -3.3948e-01,  1.2690e-01],\n",
      "        [-1.4840e-01, -3.0311e-02,  2.6272e-01,  2.2551e-01, -3.4300e-01,\n",
      "          3.2488e-01, -5.3115e-03, -1.1284e-01, -2.8586e-01,  2.1370e-01,\n",
      "          2.2728e-01,  3.1147e-01,  2.9639e-01, -6.6398e-02, -1.4023e-01,\n",
      "          2.4359e-01, -1.8149e-01,  1.6766e-01, -3.1744e-01,  4.2189e-01],\n",
      "        [ 9.0211e-02, -3.3148e-01,  1.6825e-01, -1.5576e-01,  2.2811e-01,\n",
      "          5.0698e-02,  5.1385e-02,  1.0836e-01,  5.8908e-02,  2.4811e-01,\n",
      "         -1.5493e-01, -1.5504e-01, -3.3060e-01,  2.7816e-01,  3.7267e-01,\n",
      "          1.7586e-01, -2.4492e-03,  3.8471e-02, -2.3990e-02, -6.3832e-02],\n",
      "        [ 1.7440e-01,  1.3238e-01, -6.2305e-02,  2.9512e-01, -1.1285e-01,\n",
      "         -3.1615e-01, -2.1729e-01,  2.0089e-01, -1.2807e-01,  4.4756e-01,\n",
      "         -2.6588e-02,  6.8054e-02, -2.2703e-01,  2.9226e-01, -1.6426e-01,\n",
      "         -3.1322e-01, -7.8938e-02,  2.4659e-02,  2.7503e-01, -2.1334e-01],\n",
      "        [ 3.7024e-01,  1.7592e-02, -1.4953e-01,  1.1694e-01, -5.8728e-02,\n",
      "          2.0616e-02,  7.7944e-02,  7.5006e-02, -3.4965e-01,  6.4137e-01,\n",
      "          5.2429e-01,  1.4441e-02,  9.3782e-02,  1.8580e-01,  3.0800e-02,\n",
      "          3.1342e-01, -5.1630e-01,  3.1577e-01,  1.2716e-01,  1.0214e-02],\n",
      "        [ 3.8049e-01,  1.3789e-01, -2.5778e-02, -2.6735e-02,  7.3388e-02,\n",
      "          3.4869e-03, -1.3084e-01,  1.4436e-01, -2.1891e-01,  4.7220e-01,\n",
      "          5.7341e-02, -1.4691e-01, -2.6764e-01,  3.5009e-02, -8.3446e-02,\n",
      "         -1.0421e-01, -4.5577e-01,  1.3620e-01,  3.8687e-02, -3.3481e-01],\n",
      "        [ 3.1585e-02, -1.2463e-01,  1.3425e-01,  3.1324e-01, -4.3382e-01,\n",
      "          2.5957e-01,  5.7933e-01, -1.9742e-01,  2.2639e-01, -5.6776e-02,\n",
      "          4.0474e-01,  1.4344e-01,  3.3065e-01, -1.9978e-01,  2.1371e-01,\n",
      "          1.5362e-02, -3.7464e-01, -3.4704e-01, -2.2072e-01,  6.4351e-01],\n",
      "        [-1.7886e-01,  6.8160e-01,  9.2426e-02, -1.5031e-01, -2.2136e-01,\n",
      "          3.2620e-01,  5.3522e-02, -2.6823e-02, -1.9497e-01, -2.3114e-01,\n",
      "          3.9463e-01,  3.6832e-01,  4.1382e-01, -1.2172e-01, -2.1591e-03,\n",
      "         -2.1383e-01, -8.4387e-02, -5.8140e-02, -1.7593e-01,  4.1331e-01],\n",
      "        [ 5.7628e-01, -1.9654e-01,  1.7617e-02, -4.1449e-01,  9.7729e-02,\n",
      "         -6.6695e-02, -1.0048e-01, -5.8947e-02,  5.2463e-01,  1.0386e+00,\n",
      "          4.9176e-01,  7.4277e-02,  4.8294e-01,  4.0712e-01,  5.4016e-01,\n",
      "         -2.0629e-01, -5.8190e-01, -4.2112e-01,  1.5695e-01, -1.9546e-01],\n",
      "        [ 7.1206e-02,  5.3938e-01,  1.2575e-01,  1.2668e-01, -2.6909e-01,\n",
      "          2.7891e-01,  3.5052e-01, -3.0760e-02, -2.1942e-01, -2.6121e-01,\n",
      "          1.5057e-01,  3.5981e-02,  2.2295e-01, -7.3081e-02, -1.8234e-01,\n",
      "         -3.2668e-01,  1.8506e-01,  1.3705e-01, -2.2304e-01,  2.5425e-01],\n",
      "        [ 1.1134e-01,  4.8651e-01, -2.1110e-01,  3.3998e-01,  6.2494e-02,\n",
      "          3.0338e-01,  4.2158e-02, -5.9771e-03, -3.3172e-01, -3.6717e-02,\n",
      "          4.6188e-01, -8.3335e-02,  1.7426e-01, -2.1864e-01, -1.5670e-01,\n",
      "          2.3143e-01,  2.0843e-01, -2.4319e-02, -1.1077e-01, -7.3548e-02],\n",
      "        [-1.3355e-02, -1.6160e-01,  2.4809e-01, -3.4504e-02, -8.0070e-02,\n",
      "          1.2327e-01,  3.0644e-01,  9.9344e-02,  1.3421e-01,  3.0912e-02,\n",
      "         -2.5427e-01, -4.0906e-02,  1.8455e-01, -4.2575e-03,  3.3352e-01,\n",
      "         -2.8305e-02,  3.8757e-01, -6.1297e-02, -2.3514e-01,  3.1814e-01],\n",
      "        [ 3.4467e-01, -1.3413e-01, -1.4173e-01,  1.1593e-01, -1.5340e-01,\n",
      "         -2.3570e-01, -1.2047e-01,  6.2669e-02,  2.7270e-01,  6.3564e-01,\n",
      "          1.8963e-01, -2.4799e-01,  1.1056e-01,  1.3003e-01, -3.6467e-01,\n",
      "          3.8310e-01, -1.0186e-01,  6.2202e-03, -7.3068e-02, -7.9437e-02],\n",
      "        [ 4.2329e-01,  2.1096e-01,  2.8578e-01,  1.8632e-01,  1.7166e-01,\n",
      "         -2.8213e-01, -4.8903e-01,  9.6838e-02, -3.9479e-01, -1.9741e-01,\n",
      "         -1.9201e-01, -2.9823e-01, -1.3013e-01,  4.0793e-01,  1.6111e-01,\n",
      "         -2.7698e-01, -2.4953e-01,  1.0854e-01,  2.3574e-01, -2.9515e-01],\n",
      "        [-6.3894e-02,  2.3286e-02, -7.1989e-02,  9.0635e-02, -2.3556e-01,\n",
      "          3.8351e-01,  5.3455e-01, -2.7974e-01, -8.5786e-03,  5.4316e-02,\n",
      "         -4.5157e-02,  4.3361e-01,  1.5847e-01, -1.9768e-01, -5.4954e-02,\n",
      "         -4.3851e-02,  4.8608e-02, -1.4114e-02, -3.5766e-01,  2.8979e-01]])), ('rnn.bias_ih_l0', tensor([-0.1300, -0.2909, -0.1363,  0.0647, -0.1691, -0.0595,  0.0586, -0.1740,\n",
      "         0.1710,  0.0545,  0.1154,  0.2550,  0.1115,  0.0265, -0.0576,  0.4010,\n",
      "         0.1089,  0.1548, -0.1708, -0.1050])), ('rnn.bias_hh_l0', tensor([ 0.1313,  0.1070, -0.2523, -0.0552, -0.2016,  0.2499, -0.1672, -0.2200,\n",
      "        -0.1658,  0.4177,  0.1949,  0.0746,  0.0276,  0.1704, -0.1447,  0.2730,\n",
      "        -0.0805,  0.1677, -0.3383,  0.1179])), ('fc.weight', tensor([[ 0.4117, -0.5104,  0.5938,  ..., -0.1276,  0.2393,  0.0400],\n",
      "        [ 0.1815, -0.8314,  0.7465,  ..., -0.4468,  0.1278,  0.2320],\n",
      "        [-0.5754,  1.1189, -1.0171,  ...,  0.5992,  0.2629,  0.1021],\n",
      "        ...,\n",
      "        [-0.3367, -0.4139, -0.9327,  ..., -0.4764,  0.1952,  0.0425],\n",
      "        [ 0.3438,  0.6209,  0.3196,  ...,  0.0402,  0.6407, -0.3856],\n",
      "        [-0.2982, -0.2115, -0.5700,  ..., -0.5424, -0.6056,  0.5666]])), ('fc.bias', tensor([-0.5356, -0.5106, -0.6017, -0.2229, -0.1811, -0.3412, -0.3468, -0.5267,\n",
      "        -0.1240, -0.2941, -0.1802,  0.2297,  0.0552, -0.4404, -0.0960,  0.0118,\n",
      "        -0.0555, -0.1758, -0.0676, -0.4345, -0.2569, -0.5760,  0.0323, -0.2162,\n",
      "        -0.4509, -0.4379,  0.1803, -0.1097,  0.0646, -0.1409,  0.6063,  0.2833,\n",
      "        -0.1001,  0.6945, -0.1083,  0.3740, -0.5248,  0.2254,  0.3404,  0.1232,\n",
      "        -0.1484,  0.1316,  0.2562, -0.3313, -0.4930, -0.2038, -0.3154, -0.1590,\n",
      "        -0.3579, -0.2453,  0.0399, -0.3767, -0.5733, -0.3520, -0.5247, -0.2356,\n",
      "        -0.3328, -0.2613, -0.6343, -0.5130, -0.2997, -0.4024, -0.5235, -0.2214,\n",
      "        -0.1488, -0.2413, -0.2289, -0.3972, -0.5843, -0.5156, -0.1606, -0.2894,\n",
      "         0.4891]))])\n",
      "400 1.5638065338134766\n"
     ]
    }
   ],
   "source": [
    "already_epoch, already_loss, model_, optimizer_ = load_checkpoint('model.pt')\n",
    "if model_ is not None:\n",
    "    model = model_\n",
    "    optimizer = optimizer_\n",
    "    model.train()\n",
    "print(already_epoch, already_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 1.5670\n",
      "Epoch: 20/100............. Loss: 1.5613\n",
      "Epoch: 30/100............. Loss: 1.5575\n",
      "Epoch: 40/100............. Loss: 1.5571\n",
      "Epoch: 50/100............. Loss: 1.5546\n",
      "Epoch: 60/100............. Loss: 1.5518\n",
      "Epoch: 70/100............. Loss: 1.5821\n",
      "Epoch: 80/100............. Loss: 1.5608\n",
      "Epoch: 90/100............. Loss: 1.5941\n",
      "Epoch: 100/100............. Loss: 1.6093\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "input_sen_hot_encode = input_sen_hot_encode.to(device)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    #input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_sen_hot_encode)\n",
    "    output = output.to(device)\n",
    "    target_sen_hot_encode = target_sen_hot_encode.to(device)\n",
    "    loss = criterion(output, target_sen_hot_encode.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if already_loss is not None and loss.item() < already_loss:\n",
    "    save_chekcpoint(already_epoch+n_epochs, 'model.pt', loss.item())\n",
    "if already_loss is None:\n",
    "    already_loss, already_epoch = loss.item(), n_epochs\n",
    "    save_chekcpoint(already_epoch, 'model.pt', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_two_characters(tensor_array):\n",
    "    # the output of the line below is a numpy array\n",
    "    if is_cuda is True:\n",
    "        numpy_arr = tensor_array.gpu().detach().numpy() \n",
    "    else:\n",
    "        numpy_arr = tensor_array.cpu().detach().numpy()\n",
    "    best_two = [(0, numpy_arr[0])]\n",
    "    if numpy_arr[1] > best_two[0][1]:\n",
    "        best_two.append(best_two[0])\n",
    "        best_two[0] = (1, numpy_arr[1])\n",
    "    else:\n",
    "        best_two.append((1, numpy_arr[1]))\n",
    "    for i in range(2, len(numpy_arr)):\n",
    "        if numpy_arr[i] > best_two[0][1]:\n",
    "            best_two[1] = best_two[0]\n",
    "            best_two[0] = (i, numpy_arr[i])\n",
    "        elif numpy_arr[i] > best_two[1][1]:\n",
    "            best_two[1] = (i, numpy_arr[i])\n",
    "    return best_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    character = character.to(device)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "    # print(\"out  = \", out)\n",
    "    print(out.shape)\n",
    "    # print(out[-1])\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    print(\"pob = \", prob)\n",
    "    print(prob.shape)\n",
    "    best_two = get_best_two_characters(prob)\n",
    "    print(best_two)\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    \"\"\"\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "    print(char_ind)\n",
    "    \"\"\"\n",
    "\n",
    "    return int2char[best_two[0][0]],int2char[best_two[1][0]], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char1, char2, h = predict(model, chars)\n",
    "        if chars[-1] == \" \":\n",
    "            chars.append(char2)\n",
    "        else:\n",
    "            chars.append(char1)\n",
    "        print(''.join(chars))\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12, 73)\n",
      "torch.Size([12, 73])\n",
      "pob =  tensor([3.8787e-05, 2.4160e-04, 1.9326e-03, 9.5021e-06, 2.5860e-04, 2.9183e-06,\n",
      "        5.2363e-06, 1.5479e-04, 1.7355e-05, 3.7140e-03, 4.5688e-06, 4.0426e-03,\n",
      "        3.3022e-04, 1.5019e-03, 1.0798e-04, 1.9359e-04, 7.7442e-04, 2.7498e-03,\n",
      "        7.6874e-04, 3.9358e-05, 4.4971e-05, 2.7183e-03, 1.4730e-04, 8.8566e-05,\n",
      "        1.8966e-05, 4.0042e-03, 1.0289e-02, 4.8859e-04, 2.0788e-03, 2.3806e-04,\n",
      "        3.9683e-03, 1.4308e-03, 3.2525e-04, 3.2364e-03, 4.7940e-04, 2.1157e-03,\n",
      "        3.1162e-04, 3.4703e-03, 2.1318e-03, 1.0963e-03, 2.9008e-04, 9.8247e-04,\n",
      "        1.1392e-03, 6.1691e-05, 8.0926e-06, 1.9026e-03, 1.1884e-04, 2.1119e-04,\n",
      "        3.8669e-05, 3.1507e-05, 3.9811e-02, 1.8663e-02, 8.2764e-03, 2.8553e-03,\n",
      "        1.2143e-04, 6.0557e-05, 5.4721e-02, 8.4830e-05, 9.8431e-03, 3.9843e-05,\n",
      "        2.1747e-06, 6.0907e-06, 3.2448e-06, 2.1916e-06, 2.4510e-06, 3.0319e-06,\n",
      "        2.2950e-06, 1.8204e-06, 9.1347e-06, 3.2095e-06, 7.8892e-03, 2.9919e-06,\n",
      "        7.9724e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.797241), (56, 0.054720953)]\n",
      "একসাথে মেয়ের \n",
      "(1, 13, 73)\n",
      "torch.Size([13, 73])\n",
      "pob =  tensor([9.4380e-03, 3.6657e-02, 6.1973e-03, 1.1389e-04, 6.2191e-03, 2.3126e-05,\n",
      "        2.5764e-05, 3.1900e-02, 2.3318e-04, 7.9764e-03, 1.7910e-05, 8.6300e-02,\n",
      "        1.5896e-02, 1.4615e-02, 4.1556e-03, 2.3097e-04, 1.1455e-02, 8.2128e-03,\n",
      "        1.4964e-02, 8.2391e-04, 1.8706e-04, 3.8313e-03, 1.4957e-03, 3.1959e-03,\n",
      "        1.4139e-03, 3.2366e-04, 2.4692e-02, 1.3220e-02, 2.4179e-02, 3.9148e-03,\n",
      "        3.5281e-02, 2.7259e-02, 4.6450e-03, 3.0030e-02, 9.3649e-03, 3.3039e-02,\n",
      "        1.3029e-02, 6.4517e-03, 5.3828e-03, 8.5396e-03, 1.2339e-03, 2.7048e-02,\n",
      "        3.3075e-02, 8.3152e-05, 3.1027e-05, 1.1893e-03, 1.3126e-04, 3.9196e-04,\n",
      "        1.2123e-04, 1.0770e-04, 2.7402e-03, 6.8227e-04, 3.8393e-04, 5.8541e-05,\n",
      "        1.9592e-05, 4.8694e-05, 9.1604e-04, 6.4797e-05, 5.0765e-04, 2.7363e-05,\n",
      "        8.4299e-06, 2.7434e-05, 2.1393e-05, 2.0657e-05, 1.1499e-05, 1.5688e-05,\n",
      "        1.4431e-05, 7.8965e-06, 3.0149e-05, 1.7709e-05, 4.2752e-04, 1.4040e-05,\n",
      "        4.2559e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.42559087), (11, 0.08630038)]\n",
      "একসাথে মেয়ের ক\n",
      "(1, 14, 73)\n",
      "torch.Size([14, 73])\n",
      "pob =  tensor([2.5222e-05, 5.0705e-05, 3.3843e-03, 3.8239e-05, 1.9110e-04, 1.6684e-05,\n",
      "        2.6212e-05, 4.5063e-05, 5.4147e-05, 1.3460e-03, 2.6371e-05, 4.3477e-03,\n",
      "        2.6296e-03, 1.6192e-03, 1.0084e-04, 8.0657e-04, 6.4828e-04, 2.7596e-03,\n",
      "        1.5573e-03, 5.4712e-05, 2.6829e-04, 1.6359e-02, 6.3859e-04, 2.7551e-04,\n",
      "        1.2661e-05, 1.5642e-03, 1.0144e-02, 1.9248e-02, 2.7363e-03, 4.5464e-04,\n",
      "        8.0960e-03, 1.4407e-03, 3.1095e-04, 1.2806e-02, 4.2992e-04, 1.4394e-02,\n",
      "        1.4755e-04, 2.7848e-01, 2.2712e-02, 7.8440e-04, 1.0909e-03, 1.5367e-03,\n",
      "        1.6591e-03, 5.2428e-03, 3.2032e-05, 1.0948e-02, 3.3204e-04, 4.6089e-04,\n",
      "        1.0519e-04, 2.3189e-04, 1.7583e-01, 7.3172e-02, 6.2142e-03, 2.1527e-02,\n",
      "        1.4643e-03, 1.1925e-03, 1.1181e-01, 6.4620e-04, 8.2012e-02, 5.7530e-04,\n",
      "        7.9245e-06, 2.5807e-05, 1.9270e-05, 1.6766e-05, 8.5801e-06, 2.1116e-05,\n",
      "        7.6010e-06, 7.8361e-06, 4.7448e-05, 2.1722e-05, 9.0443e-03, 2.0140e-05,\n",
      "        8.3634e-02])\n",
      "torch.Size([73])\n",
      "[(37, 0.27848262), (50, 0.1758325)]\n",
      "একসাথে মেয়ের কর\n",
      "(1, 15, 73)\n",
      "torch.Size([15, 73])\n",
      "pob =  tensor([1.5127e-05, 8.1303e-05, 3.2302e-03, 1.3223e-05, 2.2478e-04, 4.5567e-06,\n",
      "        6.6027e-06, 6.9874e-05, 1.5416e-05, 2.3421e-03, 7.2591e-06, 5.3873e-03,\n",
      "        7.7283e-04, 9.2529e-04, 6.2616e-05, 3.0577e-04, 4.9149e-04, 5.7650e-03,\n",
      "        1.2734e-03, 4.7869e-05, 5.2714e-05, 5.1047e-03, 9.2485e-05, 6.1508e-05,\n",
      "        1.0007e-05, 3.3369e-03, 1.2811e-02, 6.6680e-04, 1.2059e-03, 3.1904e-04,\n",
      "        7.8631e-03, 5.9033e-04, 1.6967e-04, 4.2905e-03, 3.6123e-04, 2.9242e-03,\n",
      "        1.8427e-04, 7.5229e-03, 9.0140e-03, 1.2710e-03, 5.2496e-04, 1.3101e-03,\n",
      "        1.2186e-03, 6.3072e-04, 7.6603e-06, 6.8721e-03, 1.3465e-04, 1.0486e-03,\n",
      "        5.9148e-05, 8.7682e-05, 8.7720e-02, 6.9691e-02, 1.4278e-02, 1.3277e-02,\n",
      "        3.7583e-04, 1.8155e-04, 2.9399e-01, 1.5840e-04, 1.3588e-02, 1.0227e-04,\n",
      "        2.4401e-06, 7.4102e-06, 3.8253e-06, 3.5373e-06, 2.5376e-06, 6.7456e-06,\n",
      "        2.5520e-06, 2.9021e-06, 1.0949e-05, 4.7672e-06, 3.5218e-02, 4.5183e-06,\n",
      "        3.8058e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.38058156), (56, 0.29398856)]\n",
      "একসাথে মেয়ের কর \n",
      "(1, 16, 73)\n",
      "torch.Size([16, 73])\n",
      "pob =  tensor([1.5675e-03, 8.0605e-03, 1.5083e-03, 4.3266e-05, 2.2576e-03, 1.0096e-05,\n",
      "        1.1299e-05, 7.3888e-03, 8.0336e-05, 2.9901e-03, 1.0584e-05, 1.2850e-02,\n",
      "        2.5640e-03, 1.7139e-03, 1.3001e-03, 3.6629e-05, 1.0983e-03, 4.1771e-03,\n",
      "        2.3529e-03, 4.1836e-04, 3.6751e-05, 2.7724e-03, 1.7420e-04, 7.3629e-04,\n",
      "        4.0549e-04, 1.6879e-04, 3.4752e-03, 1.2085e-03, 3.1339e-03, 7.6763e-04,\n",
      "        8.5372e-03, 3.0011e-03, 6.4136e-04, 4.1571e-03, 1.2904e-03, 2.5465e-03,\n",
      "        6.7892e-03, 1.2367e-03, 1.0487e-03, 2.6151e-03, 2.5308e-04, 3.1898e-03,\n",
      "        4.1534e-03, 1.7792e-05, 1.0897e-05, 2.5224e-04, 5.5258e-05, 8.9576e-05,\n",
      "        4.4596e-05, 6.0349e-05, 3.7057e-04, 1.9292e-04, 1.2804e-04, 3.4823e-05,\n",
      "        5.3121e-06, 7.6153e-06, 6.9299e-04, 1.8976e-05, 2.4055e-04, 5.3914e-06,\n",
      "        4.7676e-06, 1.2105e-05, 7.1849e-06, 7.2857e-06, 5.2380e-06, 8.2947e-06,\n",
      "        5.7371e-06, 5.0301e-06, 1.1249e-05, 6.7339e-06, 1.2188e-04, 6.4337e-06,\n",
      "        8.9479e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.89479184), (11, 0.0128499)]\n",
      "একসাথে মেয়ের কর ক\n",
      "(1, 17, 73)\n",
      "torch.Size([17, 73])\n",
      "pob =  tensor([1.0022e-05, 3.6489e-05, 5.0172e-03, 1.9281e-05, 1.3975e-04, 6.5329e-06,\n",
      "        9.6262e-06, 3.4693e-05, 2.8492e-05, 1.6470e-03, 1.0738e-05, 3.1995e-03,\n",
      "        1.0853e-03, 6.8964e-04, 5.3446e-05, 2.3833e-04, 2.4496e-04, 1.9919e-03,\n",
      "        6.9187e-04, 2.9054e-05, 6.5715e-05, 9.3590e-03, 2.1496e-04, 1.1197e-04,\n",
      "        6.7731e-06, 9.7386e-04, 4.8278e-03, 6.3622e-03, 1.0877e-03, 1.5003e-04,\n",
      "        2.8738e-03, 4.1366e-04, 9.9417e-05, 4.9747e-03, 1.2422e-04, 5.6990e-03,\n",
      "        1.0861e-04, 1.2282e-01, 8.2067e-03, 3.7847e-04, 4.3872e-04, 5.4644e-04,\n",
      "        8.1715e-04, 1.0377e-03, 1.1653e-05, 9.5897e-03, 1.5702e-04, 1.4113e-04,\n",
      "        4.2595e-05, 1.1316e-04, 1.2657e-01, 4.6904e-02, 3.4840e-03, 6.5019e-03,\n",
      "        4.5429e-04, 2.8739e-04, 1.0767e-01, 2.3578e-04, 4.6860e-02, 1.4632e-04,\n",
      "        2.9805e-06, 1.0460e-05, 7.0117e-06, 5.8534e-06, 3.3144e-06, 9.4500e-06,\n",
      "        2.9980e-06, 3.4570e-06, 1.7872e-05, 8.1896e-06, 2.4178e-03, 8.9039e-06,\n",
      "        4.6145e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.4614455), (50, 0.12656966)]\n",
      "একসাথে মেয়ের কর ক \n",
      "(1, 18, 73)\n",
      "torch.Size([18, 73])\n",
      "pob =  tensor([3.9756e-04, 1.8822e-03, 8.6930e-04, 2.8631e-05, 9.1792e-04, 7.7727e-06,\n",
      "        8.2883e-06, 1.9527e-03, 4.4133e-05, 1.3394e-03, 8.7652e-06, 3.9237e-03,\n",
      "        1.3077e-03, 3.7225e-04, 4.5491e-04, 1.4784e-05, 2.4627e-04, 1.5508e-03,\n",
      "        6.7273e-04, 2.4452e-04, 1.2875e-05, 1.1869e-03, 5.7384e-05, 2.2486e-04,\n",
      "        1.4985e-04, 6.3982e-05, 8.5424e-04, 3.6674e-04, 7.3148e-04, 2.6067e-04,\n",
      "        4.0077e-03, 6.4025e-04, 1.7699e-04, 1.0978e-03, 3.7213e-04, 4.0044e-04,\n",
      "        1.8285e-03, 6.1750e-04, 6.3862e-04, 1.2134e-03, 8.1135e-05, 1.0239e-03,\n",
      "        1.3343e-03, 1.5449e-05, 6.6596e-06, 1.6226e-04, 2.8217e-05, 4.1107e-05,\n",
      "        2.1949e-05, 5.0383e-05, 1.8361e-04, 1.7499e-04, 9.8643e-05, 4.4056e-05,\n",
      "        4.1825e-06, 5.5726e-06, 6.2596e-04, 1.3072e-05, 1.7574e-04, 3.3662e-06,\n",
      "        4.1408e-06, 8.6661e-06, 4.6364e-06, 5.0570e-06, 4.0252e-06, 6.8717e-06,\n",
      "        4.1772e-06, 4.5946e-06, 7.1661e-06, 5.0149e-06, 6.1088e-05, 4.9091e-06,\n",
      "        9.6464e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.9646385), (30, 0.004007689)]\n",
      "একসাথে মেয়ের কর ক ন\n",
      "(1, 19, 73)\n",
      "torch.Size([19, 73])\n",
      "pob =  tensor([7.0314e-06, 4.9295e-05, 1.1549e-03, 8.0500e-06, 6.8900e-05, 2.8816e-06,\n",
      "        4.6190e-06, 3.4976e-05, 1.4063e-05, 9.7260e-04, 4.7420e-06, 7.4690e-04,\n",
      "        1.5527e-04, 1.8569e-04, 2.6995e-05, 6.1072e-05, 6.8737e-05, 3.5129e-04,\n",
      "        9.9732e-05, 1.9540e-05, 1.2153e-05, 6.7232e-04, 4.4679e-05, 2.4332e-05,\n",
      "        7.4104e-06, 9.9422e-04, 1.0955e-03, 2.1829e-04, 1.9747e-04, 3.3849e-05,\n",
      "        3.4891e-04, 1.1148e-04, 4.2204e-05, 5.6867e-04, 4.7192e-05, 5.1442e-04,\n",
      "        4.7217e-05, 1.2430e-03, 4.8932e-04, 1.1690e-04, 7.2043e-05, 8.8079e-05,\n",
      "        2.4146e-04, 2.2942e-05, 3.7371e-06, 9.8502e-04, 4.3845e-05, 2.9567e-05,\n",
      "        1.3155e-05, 2.1315e-05, 2.7444e-02, 1.8395e-02, 2.7961e-03, 1.9495e-03,\n",
      "        8.6153e-05, 3.0300e-05, 3.6217e-02, 5.5543e-05, 5.6575e-03, 2.7070e-05,\n",
      "        1.5492e-06, 4.7168e-06, 2.4093e-06, 2.1067e-06, 1.8976e-06, 4.0822e-06,\n",
      "        1.9069e-06, 2.0677e-06, 6.9239e-06, 2.5565e-06, 1.1299e-03, 3.1733e-06,\n",
      "        8.9379e-01])\n",
      "torch.Size([73])\n",
      "[(72, 0.8937905), (56, 0.0362166)]\n",
      "একসাথে মেয়ের কর ক ন \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'একসাথে মেয়ের কর ক ন '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, 20, 'একসাথে মেয়ের')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "তার মস্তিষ্কটাকে যেন প্লেগ্রাউন্ড বানিয়ে ইচ্ছেমতো ছোটাছুটি করছে শব্দেরা\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
