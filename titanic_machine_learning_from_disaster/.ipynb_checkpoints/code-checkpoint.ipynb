{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, hidden_layer_sizes=(100,100), random_state=7),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> 2 100 100\n",
      "100 <class 'numpy.ndarray'>\n",
      "<class 'tuple'> 2 100 100\n",
      "100 <class 'numpy.ndarray'>\n",
      "<class 'tuple'> 2 100 100\n",
      "100 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in datasets:\n",
    "    print(type(i), len(i) , len(i[0]), len(i[1]))\n",
    "    # print(i[0])\n",
    "    print(len(i[0]), type(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 40\n",
      "[[ 0.30920485 -0.127041  ]\n",
      " [-0.48691402  0.57259859]\n",
      " [ 0.50954902 -1.66427178]\n",
      " [ 1.35242892  0.60859541]\n",
      " [ 1.89600064 -0.42653506]\n",
      " [ 0.74779523  0.54957438]\n",
      " [-1.19805934  1.40047603]\n",
      " [-1.4065875  -1.03687185]\n",
      " [-0.33075371 -0.55325533]\n",
      " [ 0.81773837  1.64300265]\n",
      " [-1.30667592 -0.60711187]\n",
      " [-0.62663858 -0.45097084]\n",
      " [-0.22120141  1.00868763]\n",
      " [-0.85151619 -0.06022663]\n",
      " [-0.59739923  0.27829883]\n",
      " [ 0.15581821 -1.14573741]\n",
      " [ 0.07813527  0.18433247]\n",
      " [ 0.24130156 -1.74371889]\n",
      " [-0.42443599  1.30854456]\n",
      " [ 0.0081454  -0.58656254]\n",
      " [ 0.03138162  1.27867747]\n",
      " [-2.02716273 -0.07552655]\n",
      " [-0.20216417  0.09829492]\n",
      " [-1.77093289 -0.15602456]\n",
      " [ 1.01975478 -0.39964896]\n",
      " [ 1.22467352 -1.45537741]\n",
      " [ 0.19895122  2.27694191]\n",
      " [ 0.27524467  0.58976897]\n",
      " [-0.9843448   1.29546509]\n",
      " [ 0.51038341 -1.09925804]\n",
      " [ 0.88796385 -1.22007405]\n",
      " [ 0.15940018 -1.05506347]\n",
      " [-0.31251963  1.85361272]\n",
      " [-1.72018154 -0.11323539]\n",
      " [-2.05161935  0.3295589 ]\n",
      " [-0.81445041  0.03881959]\n",
      " [-0.1636123  -1.53782127]\n",
      " [ 1.53916295 -0.40646646]\n",
      " [ 0.75566503  0.62671139]\n",
      " [-0.6851801   0.56462893]\n",
      " [-0.42081847 -1.03126372]\n",
      " [-1.61181827 -1.16122353]\n",
      " [-0.36004546  0.03132026]\n",
      " [ 1.10877664 -0.56596703]\n",
      " [ 1.82124821 -0.46607732]\n",
      " [ 0.24942261  0.37041953]\n",
      " [-0.04156698 -0.71850484]\n",
      " [ 0.43094924 -0.51610516]\n",
      " [ 0.23092986 -1.16563865]\n",
      " [ 0.26285439  0.08970487]\n",
      " [-1.49128776  0.68265883]\n",
      " [ 1.85584796  0.39711336]\n",
      " [-0.34194837 -0.50298565]\n",
      " [ 0.89063568 -0.73843955]\n",
      " [-1.2378428   0.7264372 ]\n",
      " [ 0.15350841  0.8912278 ]\n",
      " [-1.63601617  1.14409337]\n",
      " [-0.03734756  0.53962298]\n",
      " [-0.22413227  0.94477311]\n",
      " [-0.99471418 -0.7858591 ]] <class 'numpy.ndarray'>\n",
      "0.975 Nearest Neighbors\n",
      "0.875 Linear SVM\n",
      "0.975 RBF SVM\n",
      "0.975 Gaussian Process\n",
      "0.95 Decision Tree\n",
      "0.95 Random Forest\n",
      "0.9 Neural Net\n",
      "0.925 AdaBoost\n",
      "0.875 Naive Bayes\n",
      "0.85 QDA\n",
      "60 40\n",
      "[[ 0.33752225  0.1972156 ]\n",
      " [ 0.26007797 -0.40692781]\n",
      " [-0.77360943 -0.21251355]\n",
      " [-0.80707957 -0.38086556]\n",
      " [-1.614901   -0.74107291]\n",
      " [ 0.28714288  2.0226272 ]\n",
      " [-1.58856523 -0.80311089]\n",
      " [-0.62398345 -1.93652965]\n",
      " [-1.02059109  0.55460174]\n",
      " [ 1.21402308 -0.00750315]\n",
      " [-1.24054186  0.93944489]\n",
      " [-1.05628487 -0.08248651]\n",
      " [ 1.3540726  -0.76972033]\n",
      " [-1.8376991   0.4438167 ]\n",
      " [-0.44228055  0.79141975]\n",
      " [-0.40975282 -0.76573106]\n",
      " [-0.76542848 -1.28950516]\n",
      " [ 1.01551298 -0.54197248]\n",
      " [ 1.56603302 -0.68859753]\n",
      " [-0.58552875  0.28460164]\n",
      " [-1.03332383  0.84952455]\n",
      " [-0.65191468 -1.46468159]\n",
      " [ 0.73242037  0.75396732]\n",
      " [ 0.08107311  0.89980228]\n",
      " [ 1.1886501  -0.73998096]\n",
      " [ 0.60985187  0.23217386]\n",
      " [ 1.55395519 -1.24199011]\n",
      " [ 1.85121256 -0.004975  ]\n",
      " [-0.38448676  0.97141896]\n",
      " [-1.10713613 -0.63721127]\n",
      " [-0.38917117  1.22250794]\n",
      " [ 0.71019777  0.41754396]\n",
      " [ 1.60296587  0.6042052 ]\n",
      " [-1.29848704 -0.09834692]\n",
      " [ 0.8441058   1.90774378]\n",
      " [ 0.42445554 -1.47865265]\n",
      " [ 0.54032669 -0.11135927]\n",
      " [ 0.16261397 -0.18183213]\n",
      " [ 1.51105349  1.21666545]\n",
      " [-0.7642942  -0.03324034]\n",
      " [ 1.30539824 -1.52465769]\n",
      " [-1.78357771  1.46776645]\n",
      " [-0.0826362   0.56319091]\n",
      " [-0.07797286 -1.48563138]\n",
      " [-0.01755153 -0.84912994]\n",
      " [-1.94890625  0.92646412]\n",
      " [-1.33428073  0.28134522]\n",
      " [-0.67010608 -2.35182561]\n",
      " [-0.05495925  0.52742495]\n",
      " [ 1.26205438  1.08872015]\n",
      " [-0.64744794  1.50066709]\n",
      " [ 1.49213191  1.54360638]\n",
      " [-1.32792377  0.08300261]\n",
      " [ 0.40606432  1.46244545]\n",
      " [ 1.1654875   0.42036718]\n",
      " [-1.39691976 -1.16291727]\n",
      " [-1.53382165  1.21058973]\n",
      " [ 0.971422   -0.26947631]\n",
      " [-0.11024436  0.44022805]\n",
      " [ 0.46940181  0.77060324]] <class 'numpy.ndarray'>\n",
      "0.925 Nearest Neighbors\n",
      "0.4 Linear SVM\n",
      "0.875 RBF SVM\n",
      "0.9 Gaussian Process\n",
      "0.8 Decision Tree\n",
      "0.775 Random Forest\n",
      "0.875 Neural Net\n",
      "0.825 AdaBoost\n",
      "0.7 Naive Bayes\n",
      "0.725 QDA\n",
      "60 40\n",
      "[[-1.61978158e+00  1.29534095e+00]\n",
      " [ 1.75038375e+00 -1.62751413e-01]\n",
      " [-1.42158013e+00  7.08778815e-01]\n",
      " [ 1.36985822e+00 -8.23005038e-01]\n",
      " [ 7.30764752e-01 -1.30848519e+00]\n",
      " [-1.10032926e+00  2.24827938e-01]\n",
      " [ 7.36665588e-01 -9.92706447e-01]\n",
      " [-8.41330580e-01 -1.40813370e+00]\n",
      " [-1.61746142e+00 -6.39637623e-01]\n",
      " [ 3.42241493e-01 -1.81370696e+00]\n",
      " [ 1.09826685e+00  2.86968980e+00]\n",
      " [-1.37001245e+00  7.09447566e-01]\n",
      " [-8.15309174e-01 -2.18184983e-01]\n",
      " [ 8.62114421e-01 -1.06625993e+00]\n",
      " [ 1.24674778e+00 -7.34420290e-01]\n",
      " [-2.19997218e+00 -8.79090176e-01]\n",
      " [ 1.28873490e-01  5.08668086e-01]\n",
      " [ 3.59093208e-01 -9.94085437e-01]\n",
      " [ 3.52462913e-01  4.00213731e-01]\n",
      " [-1.17612194e+00  2.30871541e-01]\n",
      " [ 6.36816878e-01 -1.05625735e-01]\n",
      " [ 2.89911028e-01  1.26274235e+00]\n",
      " [-1.15223907e+00  2.33158784e-01]\n",
      " [ 5.46974216e-01  3.00688126e-01]\n",
      " [-2.07487125e-01 -1.08721924e+00]\n",
      " [ 7.63503659e-01 -1.87238894e-01]\n",
      " [-2.63748528e-01  4.65867288e-01]\n",
      " [ 1.59216260e+00  1.52990660e+00]\n",
      " [ 5.19724486e-01  2.31493033e-01]\n",
      " [-1.38338996e+00 -6.41211360e-01]\n",
      " [-6.04221530e-01 -8.44737004e-01]\n",
      " [-6.80766801e-01 -1.86903876e-01]\n",
      " [-4.96976512e-01 -7.10346081e-01]\n",
      " [ 1.09117696e+00  2.10333372e-01]\n",
      " [ 1.42626192e+00 -3.77664660e-01]\n",
      " [ 1.06227916e+00  1.78324450e+00]\n",
      " [-1.76927614e+00 -9.85343971e-01]\n",
      " [-1.07011443e+00  1.81445427e-01]\n",
      " [-2.13637377e+00 -8.12057499e-01]\n",
      " [-9.78154820e-01  2.44074939e-03]\n",
      " [ 2.14806426e-01  7.70482141e-01]\n",
      " [-1.38615705e+00 -2.88337481e-01]\n",
      " [ 1.42300815e+00  2.38601163e+00]\n",
      " [ 1.66784046e-01  1.37207530e+00]\n",
      " [ 8.42563547e-01 -1.25915693e-01]\n",
      " [-2.02366654e-01  3.42455235e-01]\n",
      " [ 1.75336840e+00  5.80836590e-01]\n",
      " [ 6.99741748e-01 -2.18624938e-01]\n",
      " [ 7.69467083e-01  1.21901444e+00]\n",
      " [-5.26641806e-01  1.15152640e+00]\n",
      " [-5.20653085e-01  1.11200279e+00]\n",
      " [-1.06395708e+00  3.89773425e-01]\n",
      " [-1.83796720e-01 -7.02269406e-01]\n",
      " [ 1.04855320e+00  1.82745304e+00]\n",
      " [-9.37568115e-02  3.94330302e-01]\n",
      " [ 9.64720689e-01  1.02706123e+00]\n",
      " [ 1.31625354e+00 -1.21456594e+00]\n",
      " [ 3.65780510e-01 -4.15112321e-02]\n",
      " [ 7.77722008e-01  5.70386786e-01]\n",
      " [ 1.64143191e+00  3.77089777e-01]] <class 'numpy.ndarray'>\n",
      "0.925 Nearest Neighbors\n",
      "0.925 Linear SVM\n",
      "0.95 RBF SVM\n",
      "0.925 Gaussian Process\n",
      "0.925 Decision Tree\n",
      "0.95 Random Forest\n",
      "0.95 Neural Net\n",
      "0.95 AdaBoost\n",
      "0.95 Naive Bayes\n",
      "0.925 QDA\n"
     ]
    }
   ],
   "source": [
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "    print(len(X_train), len(X_test))\n",
    "    print(X_train, type(X_train))\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(score, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_train):\n",
    "    # print (df_train.head())\n",
    "    print(df_train.info())\n",
    "    print(df_train.shape)\n",
    "    column_names = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked']\n",
    "    # changing the sex values \n",
    "    print(df_train['Sex'].unique())\n",
    "    df_train['Sex'] = df_train['Sex'].replace(['male', 'female'], [0, 1])\n",
    "    print(df_train['Sex'].unique())\n",
    "    # SipSp\n",
    "    print(df_train['SibSp'].unique())\n",
    "    # Parch\n",
    "    print(df_train['Parch'].unique())\n",
    "    # Embarked\n",
    "    print(df_train['Embarked'].unique(), len(df_train['Embarked'].unique()))\n",
    "    df_train['Embarked'] = df_train['Embarked'].fillna(0)\n",
    "    df_train['Embarked'] = df_train['Embarked'].replace(['S', 'C', 'Q'], [1, 2, 3])\n",
    "    print(df_train['Embarked'].unique(), len(df_train['Embarked'].unique()))\n",
    "    # dropping columns\n",
    "    df_train = df_train.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "    print(df_train.info())\n",
    "    # changing nan from Age\n",
    "    df_train['Age'] = df_train['Age'].fillna(0)\n",
    "    print(df_train['Age'].unique())\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Name         891 non-null    object \n",
      " 3   Sex          891 non-null    object \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        891 non-null    int64  \n",
      " 6   Parch        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    float64\n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.7+ KB\n",
      "None\n",
      "(891, 11)\n",
      "['male' 'female']\n",
      "[0 1]\n",
      "[1 0 3 4 2 5 8]\n",
      "[0 1 2 5 3 4 6]\n",
      "['S' 'C' 'Q' nan] 4\n",
      "[1 2 3 0] 4\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    int64  \n",
      " 2   Age       714 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 48.9 KB\n",
      "None\n",
      "[22.   38.   26.   35.    0.   54.    2.   27.   14.    4.   58.   20.\n",
      " 39.   55.   31.   34.   15.   28.    8.   19.   40.   66.   42.   21.\n",
      " 18.    3.    7.   49.   29.   65.   28.5   5.   11.   45.   17.   32.\n",
      " 16.   25.    0.83 30.   33.   23.   24.   46.   59.   71.   37.   47.\n",
      " 14.5  70.5  32.5  12.    9.   36.5  51.   55.5  40.5  44.    1.   61.\n",
      " 56.   50.   36.   45.5  20.5  62.   41.   52.   63.   23.5   0.92 43.\n",
      " 60.   10.   64.   13.   48.    0.75 53.   57.   80.   70.   24.5   6.\n",
      "  0.67 30.5   0.42 34.5  74.  ]\n",
      "[[ 3.      0.     22.     ...  0.      7.25    1.    ]\n",
      " [ 1.      1.     38.     ...  0.     71.2833  2.    ]\n",
      " [ 3.      1.     26.     ...  0.      7.925   1.    ]\n",
      " ...\n",
      " [ 3.      1.      0.     ...  2.     23.45    1.    ]\n",
      " [ 1.      0.     26.     ...  0.     30.      2.    ]\n",
      " [ 3.      0.     32.     ...  0.      7.75    3.    ]] [0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n",
      "623 268\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "0.6865671641791045 Nearest Neighbors\n",
      "{'C': 0.025, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "0.7649253731343284 Linear SVM\n",
      "{'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 2, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "0.6380597014925373 RBF SVM\n",
      "{'copy_X_train': True, 'kernel__k1': 1**2, 'kernel__k2': RBF(length_scale=1), 'kernel__k1__constant_value': 1.0, 'kernel__k1__constant_value_bounds': (1e-05, 100000.0), 'kernel__k2__length_scale': 1.0, 'kernel__k2__length_scale_bounds': (1e-05, 100000.0), 'kernel': 1**2 * RBF(length_scale=1), 'max_iter_predict': 100, 'multi_class': 'one_vs_rest', 'n_jobs': None, 'n_restarts_optimizer': 0, 'optimizer': 'fmin_l_bfgs_b', 'random_state': None, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.6/site-packages/sklearn/gaussian_process/kernels.py:418: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7835820895522388 Gaussian Process\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
      "0.8022388059701493 Decision Tree\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 1, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "0.7611940298507462 Random Forest\n",
      "{'activation': 'relu', 'alpha': 1, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 7, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n",
      "0.7873134328358209 Neural Net\n",
      "{'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': None}\n",
      "0.7985074626865671 AdaBoost\n",
      "{'priors': None, 'var_smoothing': 1e-09}\n",
      "0.746268656716418 Naive Bayes\n",
      "{'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}\n",
      "0.75 QDA\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    int64  \n",
      " 2   Age       891 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 48.9 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "# titanic dataset\n",
    "train_file, test_file = os.path.join('datasets', 'train.csv'), os.path.join('datasets', 'test.csv')\n",
    "df_train = pd.read_csv (train_file)   #read the csv file (put 'r' before the path string to address any special characters in the path, such as '\\'). Don't forget to put the file name at the end of the path + \".csv\"\n",
    "df_test = pd.read_csv (test_file)\n",
    "print(df_train.info(), df_test.info())\n",
    "# y remove: \n",
    "y = df_train['Survived']\n",
    "Y = y.to_numpy()\n",
    "df_train = df_train.drop(columns=['Survived'])\n",
    "# preprocess\n",
    "df_train = preprocess(df_train)\n",
    "# converting to numpy \n",
    "X = df_train.to_numpy()\n",
    "print(X, Y)\n",
    "# training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n",
    "print(len(X_train), len(X_test))\n",
    "# print(X_train, type(X_train))\n",
    "\n",
    "# iterate over classifiers\n",
    "trained_classifiers = {}\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(clf.get_params())\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(score, name)\n",
    "    trained_classifiers[name] = clf\n",
    "print(df_train.info(), df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n",
      "0       892\n",
      "1       893\n",
      "2       894\n",
      "3       895\n",
      "4       896\n",
      "       ... \n",
      "413    1305\n",
      "414    1306\n",
      "415    1307\n",
      "416    1308\n",
      "417    1309\n",
      "Name: PassengerId, Length: 418, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n",
      "(418, 11)\n",
      "['male' 'female']\n",
      "[0 1]\n",
      "[0 1 2 3 4 5 8]\n",
      "[0 1 3 2 4 6 5 9]\n",
      "['Q' 'S' 'C'] 3\n",
      "[3 1 2] 3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    int64  \n",
      " 2   Age       332 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Fare      417 non-null    float64\n",
      " 6   Embarked  418 non-null    int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 23.0 KB\n",
      "None\n",
      "[34.5  47.   62.   27.   22.   14.   30.   26.   18.   21.    0.   46.\n",
      " 23.   63.   24.   35.   45.   55.    9.   48.   50.   22.5  41.   33.\n",
      " 18.5  25.   39.   60.   36.   20.   28.   10.   17.   32.   13.   31.\n",
      " 29.   28.5  32.5   6.   67.   49.    2.   76.   43.   16.    1.   12.\n",
      " 42.   53.   26.5  40.   61.   60.5   7.   15.   54.   64.   37.   34.\n",
      " 11.5   8.    0.33 38.   57.   40.5   0.92 19.   36.5   0.75  0.83 58.\n",
      "  0.17 59.   14.5  44.    5.   51.    3.   38.5 ]\n"
     ]
    }
   ],
   "source": [
    "print(df_test.info())\n",
    "pid = df_test['PassengerId']\n",
    "print(pid)\n",
    "df_test = preprocess(df_test)\n",
    "X = df_test.to_numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
